---
layout: post
title: 스파크 시작하기
---

최근 분산 시스템을 공부하면서 아파치 프로젝트 하나를 잡고 공부해보라는 조언을 받았다. 분산 시스템 관련 아파치 프로젝트중 나에게 가장 낯익은 단어는 [ Hadoop ][1] 이었다. 그러나 요즘 인기를 끌고있다는 [ Spark ][2] 가 계속 눈에 들어왔다. 솔직히 말하면 단순히 하둡을 공부하는게 선배들의 도움을 얻기 더 쉽다. 랩실 선배께서 하둡을 이용한 연구를 하고 계시기 때문에 여러가지 조언을 들을수 있다. 그래도 *'요즘 인기있는'* 이라는 문구가 계속 맴돌아 Spark를 공부하리라 다짐했다. Spark를 공부하면서 왜 Spark가 요즘 인기있는지 Hadoop과 비교하여 무엇이 다른지 알아보고싶다.

## 스파크는 무엇인가

스파크 오피셜 사이트에서는 스파크를 다음과 같이 소개한다.

> Apache Spark™ is a fast and general engine for large-scale data processing. - spark offical site

직역하자면 *아파치 스파크는 큰 스케일의 데이터 프로세싱을 위한 빠르고 범용적인 엔진이다.*
아직 확 이해가 되질 않는다. 좀 더 알아보기로한다.


## 그래 그런데.. 스파크는 왜 빠른거야?

스파크는 RAM을 이용한 큰 스케일 데이터 프로세싱을 한다. 하둡은 매 연산을 위해 데이터를 disk에서 가져와 계산을 마친후 다시 disk로 데이터를 저장한다. 그 후 다시 disk에서 연산에 필요한 데이터를 가져온다. 이러한 disk I/O로 인해 생기는 병목현상을 예상할수 있고 실제도로 그렇다.

그러나 여기서 스파크는 in memory 




 
[1]: http://hadoop.apache.org/
[2]: http://spark.apache.org/
